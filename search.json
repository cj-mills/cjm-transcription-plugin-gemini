[
  {
    "objectID": "plugin.html",
    "href": "plugin.html",
    "title": "Gemini Plugin",
    "section": "",
    "text": "source",
    "crumbs": [
      "Gemini Plugin"
    ]
  },
  {
    "objectID": "plugin.html#testing-the-plugin",
    "href": "plugin.html#testing-the-plugin",
    "title": "Gemini Plugin",
    "section": "Testing the Plugin",
    "text": "Testing the Plugin\n\n# Test basic functionality\nplugin = GeminiPlugin()\n\n# Check availability\nprint(f\"Gemini available: {plugin.is_available()}\")\nprint(f\"Plugin name: {plugin.name}\")\nprint(f\"Plugin version: {plugin.version}\")\nprint(f\"Supported formats: {plugin.supported_formats}\")\n\nGemini available: True\nPlugin name: gemini\nPlugin version: 1.0.0\nSupported formats: ['wav', 'mp3', 'aiff', 'aac', 'ogg', 'flac']\n\n\n\n# Test configuration schema\nschema = plugin.get_config_schema()\nprint(\"Configuration properties:\")\nfor prop, details in list(schema[\"properties\"].items())[:5]:\n    print(f\"  {prop}: {details.get('description', 'No description')}\")\n\nConfiguration properties:\n  model: Gemini model to use for transcription\n  api_key: Google API key (defaults to GEMINI_API_KEY env var)\n  prompt: Prompt for transcription\n  temperature: Sampling temperature\n  top_p: Top-p sampling parameter\n\n\n\n# Test initialization (requires API key)\nif os.environ.get(\"GEMINI_API_KEY\"):\n    plugin.initialize({\"model\": \"gemini-2.5-flash\"})\n    print(f\"Initialized with model: {plugin.config['model']}\")\n    \n    # Get available models\n    models = plugin.get_available_models()\n    print(f\"\\nFound {len(models)} available models\")\n    print(\"Top 5 models:\")\n    for model in models[:5]:\n        print(f\"  - {model}\")\nelse:\n    print(\"Set GEMINI_API_KEY environment variable to test initialization\")\n\nInitialized with model: gemini-2.5-flash\n\nFound 34 available models\nTop 5 models:\n  - gemma-3n-e4b-it\n  - gemma-3n-e2b-it\n  - gemma-3-4b-it\n  - gemma-3-27b-it\n  - gemma-3-1b-it",
    "crumbs": [
      "Gemini Plugin"
    ]
  },
  {
    "objectID": "plugin.html#testing-dynamic-token-limits",
    "href": "plugin.html#testing-dynamic-token-limits",
    "title": "Gemini Plugin",
    "section": "Testing Dynamic Token Limits",
    "text": "Testing Dynamic Token Limits\nTest that max_output_tokens is dynamically updated based on the selected model’s output_token_limit.\n\n# Test dynamic token limit updates\nif os.environ.get(\"GEMINI_API_KEY\"):\n    # Initialize plugin\n    plugin = GeminiPlugin()\n    plugin.initialize({\"model\": \"gemini-2.5-flash\"})\n    \n    # Check token limits for different models\n    print(\"Token limits for different models:\")\n    print(\"-\" * 50)\n    \n    # Display token limits that were discovered\n    for model_name in list(plugin.model_token_limits.keys())[:5]:\n        token_limit = plugin.model_token_limits[model_name]\n        print(f\"{model_name}: {token_limit:,} tokens\")\n    \n    print(\"\\nCurrent configuration:\")\n    print(f\"Model: {plugin.config['model']}\")\n    print(f\"Max output tokens: {plugin.config['max_output_tokens']:,}\")\n    \n    # Get model info\n    model_info = plugin.get_model_info()\n    print(f\"\\nModel info for {model_info['name']}:\")\n    print(f\"  Output token limit: {model_info['output_token_limit']:,}\")\n    print(f\"  Current max_output_tokens: {model_info['current_max_output_tokens']:,}\")\nelse:\n    print(\"Set GEMINI_API_KEY environment variable to test token limits\")\n\nToken limits for different models:\n--------------------------------------------------\ngemini-2.5-pro-preview-03-25: 65,536 tokens\ngemini-2.5-flash-preview-05-20: 65,536 tokens\ngemini-2.5-flash: 65,536 tokens\ngemini-2.5-flash-lite-preview-06-17: 65,536 tokens\ngemini-2.5-pro-preview-05-06: 65,536 tokens\n\nCurrent configuration:\nModel: gemini-2.5-flash\nMax output tokens: 65,536\n\nModel info for gemini-2.5-flash:\n  Output token limit: 65,536\n  Current max_output_tokens: 65,536\n\n\n\n# Test switching models and automatic token limit update\nif os.environ.get(\"GEMINI_API_KEY\"):\n    # Switch to a different model\n    print(\"Testing model switching and token limit updates:\")\n    print(\"-\" * 50)\n    \n    test_models = [\"gemini-2.5-flash\", \"gemini-1.5-pro\", \"gemini-2.0-flash\"]\n    \n    for model_name in test_models:\n        if model_name in plugin.model_token_limits:\n            # Update configuration with new model\n            plugin.update_config({\"model\": model_name})\n            \n            print(f\"\\nSwitched to model: {model_name}\")\n            print(f\"  Token limit: {plugin.model_token_limits[model_name]:,}\")\n            print(f\"  Config max_output_tokens: {plugin.config['max_output_tokens']:,}\")\n            \n            # Verify schema is updated\n            schema = plugin.get_config_schema()\n            max_tokens_prop = schema[\"properties\"][\"max_output_tokens\"]\n            print(f\"  Schema maximum: {max_tokens_prop['maximum']:,}\")\n            print(f\"  Schema default: {max_tokens_prop['default']:,}\")\nelse:\n    print(\"Set GEMINI_API_KEY environment variable to test model switching\")\n\nTesting model switching and token limit updates:\n--------------------------------------------------\n\nSwitched to model: gemini-2.5-flash\n  Token limit: 65,536\n  Config max_output_tokens: 65,536\n  Schema maximum: 65,536\n  Schema default: 65,536\n\nSwitched to model: gemini-2.0-flash\n  Token limit: 8,192\n  Config max_output_tokens: 8,192\n  Schema maximum: 65,536\n  Schema default: 65,536\n\n\n\n# Test execution with runtime model override\nif os.environ.get(\"GEMINI_API_KEY\"):\n    print(\"Testing runtime model override:\")\n    print(\"-\" * 50)\n    \n    # Create test audio\n    import numpy as np\n    from cjm_transcription_plugin_system.core import AudioData\n    \n    test_audio = AudioData(\n        samples=np.random.randn(16000).astype(np.float32) * 0.1,\n        sample_rate=16000,\n        duration=1.0,\n        filepath=None,\n        metadata={}\n    )\n    \n    # Current model and token limit\n    print(f\"Current model: {plugin.config['model']}\")\n    print(f\"Current max_output_tokens: {plugin.config['max_output_tokens']:,}\")\n    \n    # Execute with a different model at runtime\n    override_model = \"gemini-2.0-flash\" if plugin.config['model'] != \"gemini-2.0-flash\" else \"gemini-2.5-flash\"\n    \n    if override_model in plugin.model_token_limits:\n        print(f\"\\nExecuting with override model: {override_model}\")\n        print(f\"Expected token limit: {plugin.model_token_limits[override_model]:,}\")\n        \n        try:\n            result = plugin.execute(\n                test_audio,\n                model=override_model,\n                prompt=\"This is a test audio signal.\"\n            )\n            \n            print(f\"\\nTranscription metadata:\")\n            print(f\"  Model used: {result.metadata['model']}\")\n            print(f\"  Max output tokens: {result.metadata['max_output_tokens']:,}\")\n            \n            # Check if config was updated\n            print(f\"\\nConfig after execution:\")\n            print(f\"  Model: {plugin.config['model']}\")\n            print(f\"  Max output tokens: {plugin.config['max_output_tokens']:,}\")\n            \n        except Exception as e:\n            print(f\"Execution error (expected for random audio): {e}\")\nelse:\n    print(\"Set GEMINI_API_KEY environment variable to test runtime override\")\n\nSet GEMINI_API_KEY environment variable to test runtime override",
    "crumbs": [
      "Gemini Plugin"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cjm-transcription-plugin-gemini",
    "section": "",
    "text": "pip install cjm_transcription_plugin_gemini",
    "crumbs": [
      "cjm-transcription-plugin-gemini"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "cjm-transcription-plugin-gemini",
    "section": "",
    "text": "pip install cjm_transcription_plugin_gemini",
    "crumbs": [
      "cjm-transcription-plugin-gemini"
    ]
  },
  {
    "objectID": "index.html#project-structure",
    "href": "index.html#project-structure",
    "title": "cjm-transcription-plugin-gemini",
    "section": "Project Structure",
    "text": "Project Structure\nnbs/\n└── plugin.ipynb # Plugin implementation for Google Gemini API transcription\nTotal: 1 notebook across 1 directory",
    "crumbs": [
      "cjm-transcription-plugin-gemini"
    ]
  },
  {
    "objectID": "index.html#module-dependencies",
    "href": "index.html#module-dependencies",
    "title": "cjm-transcription-plugin-gemini",
    "section": "Module Dependencies",
    "text": "Module Dependencies\ngraph LR\n    plugin[plugin&lt;br/&gt;Gemini Plugin]\n\nNo cross-module dependencies detected.",
    "crumbs": [
      "cjm-transcription-plugin-gemini"
    ]
  },
  {
    "objectID": "index.html#cli-reference",
    "href": "index.html#cli-reference",
    "title": "cjm-transcription-plugin-gemini",
    "section": "CLI Reference",
    "text": "CLI Reference\nNo CLI commands found in this project.",
    "crumbs": [
      "cjm-transcription-plugin-gemini"
    ]
  },
  {
    "objectID": "index.html#module-overview",
    "href": "index.html#module-overview",
    "title": "cjm-transcription-plugin-gemini",
    "section": "Module Overview",
    "text": "Module Overview\nDetailed documentation for each module in the project:\n\nGemini Plugin (plugin.ipynb)\n\nPlugin implementation for Google Gemini API transcription\n\n\nImport\nfrom cjm_transcription_plugin_gemini.plugin import (\n    GeminiPlugin\n)\n\n\nFunctions\n@patch\ndef _get_api_key(\n    self:GeminiPlugin\n) -&gt; str:  # Returns the API key string\n    \"Get API key from config or environment.\"\n@patch\ndef _refresh_available_models(\n    self:GeminiPlugin\n) -&gt; List[str]:  # Returns list of available model names\n    \"Fetch and filter available models from Gemini API.\"\n@patch\ndef _update_max_tokens_for_model(\n    self:GeminiPlugin,\n    model_name: str  # Model name to update tokens for\n) -&gt; None\n    \"Update max_output_tokens config based on the model's token limit.\"\n@patch\ndef update_config(\n    self:GeminiPlugin,\n    config: Dict[str, Any]  # New configuration values\n) -&gt; None\n    \"Update plugin configuration, adjusting max_tokens if model changes.\"\n@patch\ndef _prepare_audio(\n    self:GeminiPlugin,\n    audio: Union[AudioData, str, Path]  # Audio data object or path to audio file\n) -&gt; Tuple[Path, bool]:  # Returns tuple of (processed audio path, whether temp file was created)\n    \"Prepare audio file for upload.\"\n@patch\ndef _upload_audio_file(\n    self:GeminiPlugin,\n    audio_path: Path  # Path to audio file to upload\n) -&gt; Any:  # Returns uploaded file object\n    \"Upload audio file to Gemini API.\"\n@patch\ndef _delete_uploaded_file(\n    self:GeminiPlugin,\n    file_name: str  # Name of file to delete\n) -&gt; None\n    \"Delete an uploaded file from Gemini API.\"\n@patch\ndef cleanup(\n    self:GeminiPlugin\n) -&gt; None\n    \"Clean up resources.\"\n@patch\ndef get_available_models(\n    self:GeminiPlugin\n) -&gt; List[str]:  # Returns list of available model names\n    \"Get list of available audio-capable models.\"\n@patch\ndef get_model_info(\n    self:GeminiPlugin,\n    model_name: Optional[str] = None  # Model name to get info for, defaults to current model\n) -&gt; Dict[str, Any]:  # Returns dict with model information\n    \"Get information about a specific model including token limits.\"\n@patch\ndef supports_streaming(\n    self:GeminiPlugin\n) -&gt; bool:  # Returns True if streaming is supported\n    \"Check if this plugin supports streaming transcription.\"\n@patch\ndef execute_stream(\n    self:GeminiPlugin,\n    audio: Union[AudioData, str, Path],  # Audio data object or path to audio file\n    **kwargs  # Additional arguments to override config\n) -&gt; Generator[str, None, TranscriptionResult]:  # Yields text chunks, returns final result\n    \"Stream transcription results chunk by chunk.\"\n\n\nClasses\nclass GeminiPlugin:\n    def __init__(self):\n        \"\"\"Initialize the Gemini plugin with default configuration.\"\"\"\n        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n        self.config = {}\n        self.client = None\n        self.available_models = []\n        self.model_token_limits = {}  # Store model name -&gt; output_token_limit mapping\n        self.uploaded_files = []  # Track uploaded files for cleanup\n    \n    @property\n    def name(\n        self\n    ) -&gt; str:  # Returns the plugin name identifier\n    \"Google Gemini API transcription plugin.\"\n    \n    def __init__(self):\n            \"\"\"Initialize the Gemini plugin with default configuration.\"\"\"\n            self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n            self.config = {}\n            self.client = None\n            self.available_models = []\n            self.model_token_limits = {}  # Store model name -&gt; output_token_limit mapping\n            self.uploaded_files = []  # Track uploaded files for cleanup\n        \n        @property\n        def name(\n            self\n        ) -&gt; str:  # Returns the plugin name identifier\n        \"Initialize the Gemini plugin with default configuration.\"\n    \n    def name(\n            self\n        ) -&gt; str:  # Returns the plugin name identifier\n        \"Return the plugin name identifier.\"\n    \n    def version(\n            self\n        ) -&gt; str:  # Returns the plugin version string\n        \"Return the plugin version string.\"\n    \n    def supported_formats(\n            self\n        ) -&gt; List[str]:  # Returns list of supported audio formats\n        \"Return list of supported audio file formats.\"\n    \n    def get_config_schema(\n            current_model: str=\"gemini-2.5-flash\",\n            max_tokens: int=65536,\n            available_models: List[str]=None\n        ) -&gt; Dict[str, Any]:  # Returns JSON schema for configuration validation\n        \"Return configuration schema for Gemini.\"\n    \n    def get_current_config(\n            self\n        ) -&gt; Dict[str, Any]:  # Returns the merged configuration dictionary\n        \"Return current configuration.\"\n    \n    def initialize(\n            self,\n            config: Optional[Dict[str, Any]] = None  # Configuration dictionary to override defaults\n        ) -&gt; None\n        \"Initialize the plugin with configuration.\"\n    \n    def execute(\n            self,\n            audio: Union[AudioData, str, Path],  # Audio data object or path to audio file\n            **kwargs # Additional arguments to override config\n        ) -&gt; TranscriptionResult:  # Returns transcription result object\n        \"Transcribe audio using Gemini.\"\n    \n    def is_available(\n            self\n        ) -&gt; bool:  # Returns True if the Gemini API is available\n        \"Check if Gemini API is available.\"",
    "crumbs": [
      "cjm-transcription-plugin-gemini"
    ]
  }
]