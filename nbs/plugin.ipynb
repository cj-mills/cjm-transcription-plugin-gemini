{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9385067",
   "metadata": {},
   "source": [
    "# Gemini Plugin\n",
    "\n",
    "> Plugin implementation for Google Gemini API transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3341181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import logging\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, List, Union, Tuple\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from google import genai\n",
    "    from google.genai import types\n",
    "    GEMINI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GEMINI_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from cjm_ffmpeg_utils.core import FFMPEG_AVAILABLE\n",
    "    from cjm_ffmpeg_utils.audio import downsample_audio\n",
    "except ImportError:\n",
    "    FFMPEG_AVAILABLE = False\n",
    "    \n",
    "from cjm_transcription_plugin_system.plugin_interface import PluginInterface\n",
    "from cjm_transcription_plugin_system.core import AudioData, TranscriptionResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0932b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GeminiPlugin(PluginInterface):\n",
    "    \"\"\"Google Gemini API transcription plugin.\"\"\"\n",
    "    \n",
    "    # Default audio-capable models (can be overridden)\n",
    "    DEFAULT_AUDIO_MODELS = [\n",
    "        \"gemini-2.5-flash\",\n",
    "        \"gemini-2.5-flash-preview-05-20\",\n",
    "        \"gemini-2.5-pro\",\n",
    "        \"gemini-2.5-pro-preview-05-06\",\n",
    "        \"gemini-2.0-flash\",\n",
    "        \"gemini-2.0-flash-exp\",\n",
    "        \"gemini-1.5-flash\",\n",
    "        \"gemini-1.5-flash-latest\",\n",
    "        \"gemini-1.5-pro\",\n",
    "        \"gemini-1.5-pro-latest\",\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Gemini plugin with default configuration.\"\"\"\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{type(self).__name__}\")\n",
    "        self.config = {}\n",
    "        self.client = None\n",
    "        self.available_models = []\n",
    "    \n",
    "    @property\n",
    "    def name(\n",
    "        self\n",
    "    ) -> str:  # Returns the plugin name identifier\n",
    "        \"\"\"Return the plugin name identifier.\"\"\"\n",
    "        return \"gemini\"\n",
    "    \n",
    "    @property\n",
    "    def version(\n",
    "        self\n",
    "    ) -> str:  # Returns the plugin version string\n",
    "        \"\"\"Return the plugin version string.\"\"\"\n",
    "        return \"1.0.0\"\n",
    "    \n",
    "    @property\n",
    "    def supported_formats(\n",
    "        self\n",
    "    ) -> List[str]:  # Returns list of supported audio formats\n",
    "        \"\"\"Return list of supported audio file formats.\"\"\"\n",
    "        return [\"wav\", \"mp3\", \"aiff\", \"aac\", \"ogg\", \"flac\"]\n",
    "    \n",
    "    def get_config_schema(\n",
    "        self\n",
    "    ) -> Dict[str, Any]:  # Returns JSON schema for configuration validation\n",
    "        \"\"\"Return configuration schema for Gemini.\"\"\"\n",
    "        return {\n",
    "            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "            \"type\": \"object\",\n",
    "            \"title\": \"Gemini Configuration\",\n",
    "            \"properties\": {\n",
    "                \"model\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"default\": \"gemini-2.5-flash\",\n",
    "                    \"description\": \"Gemini model to use for transcription\",\n",
    "                    \"enum\": self.DEFAULT_AUDIO_MODELS  # Will be updated dynamically\n",
    "                },\n",
    "                \"api_key\": {\n",
    "                    \"type\": [\"string\", \"null\"],\n",
    "                    \"default\": None,\n",
    "                    \"description\": \"Google API key (defaults to GEMINI_API_KEY env var)\"\n",
    "                },\n",
    "                \"prompt\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"default\": \"Generate a transcription of the audio, only extract speech and ignore background audio.\",\n",
    "                    \"description\": \"Prompt for transcription\"\n",
    "                },\n",
    "                \"temperature\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"minimum\": 0.0,\n",
    "                    \"maximum\": 2.0,\n",
    "                    \"default\": 0.0,\n",
    "                    \"description\": \"Sampling temperature\"\n",
    "                },\n",
    "                \"top_p\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"minimum\": 0.0,\n",
    "                    \"maximum\": 1.0,\n",
    "                    \"default\": 0.95,\n",
    "                    \"description\": \"Top-p sampling parameter\"\n",
    "                },\n",
    "                \"max_output_tokens\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"minimum\": 1,\n",
    "                    \"maximum\": 65536,\n",
    "                    \"default\": 65536,\n",
    "                    \"description\": \"Maximum number of output tokens\"\n",
    "                },\n",
    "                \"seed\": {\n",
    "                    \"type\": [\"integer\", \"null\"],\n",
    "                    \"default\": None,\n",
    "                    \"description\": \"Random seed for reproducibility\"\n",
    "                },\n",
    "                \"response_mime_type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"text/plain\", \"application/json\"],\n",
    "                    \"default\": \"text/plain\",\n",
    "                    \"description\": \"Response MIME type\"\n",
    "                },\n",
    "                \"downsample_audio\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"default\": False,\n",
    "                    \"description\": \"Downsample audio before uploading (requires ffmpeg)\"\n",
    "                },\n",
    "                \"downsample_rate\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"enum\": [8000, 16000, 22050, 44100],\n",
    "                    \"default\": 16000,\n",
    "                    \"description\": \"Target sample rate for downsampling\"\n",
    "                },\n",
    "                \"downsample_channels\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"enum\": [1, 2],\n",
    "                    \"default\": 1,\n",
    "                    \"description\": \"Number of audio channels (1=mono, 2=stereo)\"\n",
    "                },\n",
    "                \"safety_settings\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"OFF\", \"BLOCK_NONE\", \"BLOCK_FEW\", \"BLOCK_SOME\", \"BLOCK_MOST\"],\n",
    "                    \"default\": \"OFF\",\n",
    "                    \"description\": \"Safety filter threshold\"\n",
    "                },\n",
    "                \"auto_refresh_models\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"default\": True,\n",
    "                    \"description\": \"Automatically refresh available models list\"\n",
    "                },\n",
    "                \"model_filter\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"default\": [],\n",
    "                    \"description\": \"Keywords to exclude from model names (e.g., ['tts', 'image'])\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"model\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    \n",
    "    def get_current_config(\n",
    "        self\n",
    "    ) -> Dict[str, Any]:  # Returns the merged configuration dictionary\n",
    "        \"\"\"Return current configuration.\"\"\"\n",
    "        defaults = self.get_config_defaults()\n",
    "        return {**defaults, **self.config}\n",
    "    \n",
    "    def _get_api_key(\n",
    "        self\n",
    "    ) -> str:  # Returns the API key string\n",
    "        \"\"\"Get API key from config or environment.\"\"\"\n",
    "        api_key = self.config.get(\"api_key\")\n",
    "        if not api_key:\n",
    "            api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"No API key provided. Set GEMINI_API_KEY environment variable or provide api_key in config\")\n",
    "        return api_key\n",
    "    \n",
    "    def _refresh_available_models(\n",
    "        self\n",
    "    ) -> List[str]:  # Returns list of available model names\n",
    "        \"\"\"Fetch and filter available models from Gemini API.\"\"\"\n",
    "        try:\n",
    "            if not self.client:\n",
    "                return self.DEFAULT_AUDIO_MODELS\n",
    "            \n",
    "            # Get all models that support content generation\n",
    "            all_models = list(self.client.models.list())\n",
    "            gen_models = [model for model in all_models if 'generateContent' in model.supported_actions]\n",
    "            \n",
    "            # Extract model names and apply filters\n",
    "            model_filter = self.config.get(\"model_filter\", [])\n",
    "            if not model_filter:\n",
    "                model_filter = ['tts', 'image', 'learn']  # Default exclusions\n",
    "            \n",
    "            filtered_names = []\n",
    "            for model in gen_models:\n",
    "                model_name = model.name.removeprefix('models/')\n",
    "                # Skip if any filter keyword is in the model name\n",
    "                if not any(keyword in model_name.lower() for keyword in model_filter):\n",
    "                    filtered_names.append(model_name)\n",
    "            \n",
    "            # Sort with newest/best models first\n",
    "            filtered_names.sort(reverse=True)\n",
    "            \n",
    "            self.logger.info(f\"Found {len(filtered_names)} audio-capable models\")\n",
    "            return filtered_names if filtered_names else self.DEFAULT_AUDIO_MODELS\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not fetch models from API: {e}. Using defaults.\")\n",
    "            return self.DEFAULT_AUDIO_MODELS\n",
    "    \n",
    "    def initialize(\n",
    "        self,\n",
    "        config: Optional[Dict[str, Any]] = None  # Configuration dictionary to override defaults\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the plugin with configuration.\"\"\"\n",
    "        if config:\n",
    "            is_valid, error = self.validate_config(config)\n",
    "            if not is_valid:\n",
    "                raise ValueError(f\"Invalid configuration: {error}\")\n",
    "        \n",
    "        # Merge with defaults\n",
    "        defaults = self.get_config_defaults()\n",
    "        self.config = {**defaults, **(config or {})}\n",
    "        \n",
    "        # Initialize client\n",
    "        try:\n",
    "            api_key = self._get_api_key()\n",
    "            self.client = genai.Client(api_key=api_key)\n",
    "            \n",
    "            # Refresh available models if enabled\n",
    "            if self.config.get(\"auto_refresh_models\", True):\n",
    "                self.available_models = self._refresh_available_models()\n",
    "                # Update schema with actual available models\n",
    "                schema = self.get_config_schema()\n",
    "                schema[\"properties\"][\"model\"][\"enum\"] = self.available_models\n",
    "            else:\n",
    "                self.available_models = self.DEFAULT_AUDIO_MODELS\n",
    "                \n",
    "            self.logger.info(f\"Initialized Gemini plugin with model '{self.config['model']}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to initialize Gemini client: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _prepare_audio(\n",
    "        self,\n",
    "        audio: Union[AudioData, str, Path]  # Audio data object or path to audio file\n",
    "    ) -> Tuple[Path, bool]:  # Returns tuple of (processed audio path, whether temp file was created)\n",
    "        \"\"\"Prepare audio file for upload.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (audio_path, is_temp_file)\n",
    "        \"\"\"\n",
    "        temp_created = False\n",
    "        \n",
    "        if isinstance(audio, (str, Path)):\n",
    "            audio_path = Path(audio)\n",
    "        elif isinstance(audio, AudioData):\n",
    "            # Save AudioData to temporary file\n",
    "            import soundfile as sf\n",
    "            temp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "            \n",
    "            audio_array = audio.samples\n",
    "            # Convert to mono if stereo\n",
    "            if audio_array.ndim > 1:\n",
    "                audio_array = audio_array.mean(axis=1)\n",
    "            \n",
    "            # Ensure float32 and normalized\n",
    "            if audio_array.dtype != np.float32:\n",
    "                audio_array = audio_array.astype(np.float32)\n",
    "            if audio_array.max() > 1.0:\n",
    "                audio_array = audio_array / np.abs(audio_array).max()\n",
    "            \n",
    "            sf.write(temp_file.name, audio_array, audio.sample_rate)\n",
    "            audio_path = Path(temp_file.name)\n",
    "            temp_created = True\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported audio input type: {type(audio)}\")\n",
    "        \n",
    "        # Optionally downsample audio\n",
    "        if self.config.get(\"downsample_audio\", False) and FFMPEG_AVAILABLE:\n",
    "            try:\n",
    "                downsampled = audio_path.with_stem(f\"{audio_path.stem}_downsampled\")\n",
    "                downsample_audio(\n",
    "                    audio_path,\n",
    "                    downsampled,\n",
    "                    # sample_rate=self.config.get(\"downsample_rate\", 16000),\n",
    "                    # channels=self.config.get(\"downsample_channels\", 1)\n",
    "                )\n",
    "                \n",
    "                # Clean up original temp file if created\n",
    "                if temp_created:\n",
    "                    audio_path.unlink()\n",
    "                \n",
    "                audio_path = downsampled\n",
    "                temp_created = True\n",
    "                self.logger.info(f\"Downsampled audio to {self.config['downsample_rate']}Hz\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Failed to downsample audio: {e}\")\n",
    "        \n",
    "        return audio_path, temp_created\n",
    "    \n",
    "    def execute(\n",
    "        self,\n",
    "        audio: Union[AudioData, str, Path],  # Audio data object or path to audio file\n",
    "        **kwargs # Additional arguments to override config\n",
    "    ) -> TranscriptionResult:  # Returns transcription result object\n",
    "        \"\"\"Transcribe audio using Gemini.\"\"\"\n",
    "        if not self.client:\n",
    "            raise RuntimeError(\"Plugin not initialized. Call initialize() first.\")\n",
    "        \n",
    "        # Prepare audio file\n",
    "        audio_path, temp_created = self._prepare_audio(audio)\n",
    "        \n",
    "        try:\n",
    "            # Merge runtime kwargs with config\n",
    "            exec_config = {**self.config, **kwargs}\n",
    "            \n",
    "            # Read audio file\n",
    "            with open(audio_path, 'rb') as f:\n",
    "                audio_bytes = f.read()\n",
    "            \n",
    "            # Determine MIME type\n",
    "            suffix = audio_path.suffix.lower()\n",
    "            mime_map = {\n",
    "                '.wav': 'audio/wav',\n",
    "                '.mp3': 'audio/mp3',\n",
    "                '.aiff': 'audio/aiff',\n",
    "                '.aac': 'audio/aac',\n",
    "                '.ogg': 'audio/ogg',\n",
    "                '.flac': 'audio/flac'\n",
    "            }\n",
    "            mime_type = mime_map.get(suffix, 'audio/wav')\n",
    "            \n",
    "            # Create audio content part\n",
    "            audio_content = types.Part.from_bytes(\n",
    "                data=audio_bytes,\n",
    "                mime_type=mime_type\n",
    "            )\n",
    "            \n",
    "            # Prepare generation config\n",
    "            generate_config = types.GenerateContentConfig(\n",
    "                response_mime_type=exec_config[\"response_mime_type\"],\n",
    "                temperature=exec_config[\"temperature\"],\n",
    "                top_p=exec_config[\"top_p\"],\n",
    "                max_output_tokens=exec_config[\"max_output_tokens\"],\n",
    "                seed=exec_config.get(\"seed\"),\n",
    "                safety_settings=[\n",
    "                    types.SafetySetting(\n",
    "                        category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "                        threshold=exec_config[\"safety_settings\"]\n",
    "                    ),\n",
    "                    types.SafetySetting(\n",
    "                        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "                        threshold=exec_config[\"safety_settings\"]\n",
    "                    ),\n",
    "                    types.SafetySetting(\n",
    "                        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "                        threshold=exec_config[\"safety_settings\"]\n",
    "                    ),\n",
    "                    types.SafetySetting(\n",
    "                        category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "                        threshold=exec_config[\"safety_settings\"]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Prepare contents\n",
    "            prompt = exec_config[\"prompt\"]\n",
    "            contents = [prompt, audio_content]\n",
    "            \n",
    "            # Generate transcription\n",
    "            self.logger.info(f\"Transcribing with Gemini model: {exec_config['model']}\")\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=exec_config[\"model\"],\n",
    "                contents=contents,\n",
    "                config=generate_config\n",
    "            )\n",
    "            \n",
    "            # Extract text from response\n",
    "            transcribed_text = response.text if hasattr(response, 'text') else str(response)\n",
    "            \n",
    "            # Create result\n",
    "            result = TranscriptionResult(\n",
    "                text=transcribed_text.strip(),\n",
    "                confidence=None,  # Gemini doesn't provide confidence scores\n",
    "                segments=None,  # Gemini doesn't provide segments by default\n",
    "                metadata={\n",
    "                    \"model\": exec_config[\"model\"],\n",
    "                    \"temperature\": exec_config[\"temperature\"],\n",
    "                    \"top_p\": exec_config[\"top_p\"],\n",
    "                    \"prompt\": prompt[:100] + \"...\" if len(prompt) > 100 else prompt\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"Transcription completed: {len(transcribed_text.split())} words\")\n",
    "            return result\n",
    "            \n",
    "        finally:\n",
    "            # Clean up temporary file\n",
    "            if temp_created:\n",
    "                try:\n",
    "                    audio_path.unlink()\n",
    "                except Exception:\n",
    "                    pass\n",
    "    \n",
    "    def is_available(\n",
    "        self\n",
    "    ) -> bool:  # Returns True if the Gemini API is available\n",
    "        \"\"\"Check if Gemini API is available.\"\"\"\n",
    "        return GEMINI_AVAILABLE\n",
    "    \n",
    "    def cleanup(\n",
    "        self\n",
    "    ) -> None:\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        self.client = None\n",
    "        self.logger.info(\"Cleanup completed\")\n",
    "    \n",
    "    def get_available_models(\n",
    "        self\n",
    "    ) -> List[str]:  # Returns list of available model names\n",
    "        \"\"\"Get list of available audio-capable models.\"\"\"\n",
    "        if self.config.get(\"auto_refresh_models\", True) and self.client:\n",
    "            self.available_models = self._refresh_available_models()\n",
    "        return self.available_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93916e0",
   "metadata": {},
   "source": [
    "## Testing the Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed7728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini available: True\n",
      "Plugin name: gemini\n",
      "Plugin version: 1.0.0\n",
      "Supported formats: ['wav', 'mp3', 'aiff', 'aac', 'ogg', 'flac']\n"
     ]
    }
   ],
   "source": [
    "# Test basic functionality\n",
    "plugin = GeminiPlugin()\n",
    "\n",
    "# Check availability\n",
    "print(f\"Gemini available: {plugin.is_available()}\")\n",
    "print(f\"Plugin name: {plugin.name}\")\n",
    "print(f\"Plugin version: {plugin.version}\")\n",
    "print(f\"Supported formats: {plugin.supported_formats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration properties:\n",
      "  model: Gemini model to use for transcription\n",
      "  api_key: Google API key (defaults to GEMINI_API_KEY env var)\n",
      "  prompt: Prompt for transcription\n",
      "  temperature: Sampling temperature\n",
      "  top_p: Top-p sampling parameter\n"
     ]
    }
   ],
   "source": [
    "# Test configuration schema\n",
    "schema = plugin.get_config_schema()\n",
    "print(\"Configuration properties:\")\n",
    "for prop, details in list(schema[\"properties\"].items())[:5]:\n",
    "    print(f\"  {prop}: {details.get('description', 'No description')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9d5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized with model: gemini-2.5-flash\n",
      "\n",
      "Found 36 available models\n",
      "Top 5 models:\n",
      "  - gemma-3n-e4b-it\n",
      "  - gemma-3n-e2b-it\n",
      "  - gemma-3-4b-it\n",
      "  - gemma-3-27b-it\n",
      "  - gemma-3-1b-it\n"
     ]
    }
   ],
   "source": [
    "# Test initialization (requires API key)\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    plugin.initialize({\"model\": \"gemini-2.5-flash\"})\n",
    "    print(f\"Initialized with model: {plugin.config['model']}\")\n",
    "    \n",
    "    # Get available models\n",
    "    models = plugin.get_available_models()\n",
    "    print(f\"\\nFound {len(models)} available models\")\n",
    "    print(\"Top 5 models:\")\n",
    "    for model in models[:5]:\n",
    "        print(f\"  - {model}\")\n",
    "else:\n",
    "    print(\"Set GEMINI_API_KEY environment variable to test initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a52dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
