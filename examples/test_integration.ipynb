{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138589dd",
   "metadata": {},
   "source": [
    "# Test Plugin Integration\n",
    "\n",
    "> Test the Gemini plugin with the transcription plugin system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3269cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from cjm_transcription_plugin_system.plugin_manager import PluginManager\n",
    "from cjm_transcription_plugin_system.core import AudioData\n",
    "from cjm_transcription_plugin_gemini.plugin import GeminiPlugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddce9d3",
   "metadata": {},
   "source": [
    "## Test Direct Plugin Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32268f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin: gemini v1.0.0\n",
      "Available: True\n",
      "Supported formats: wav, mp3, aiff, aac, ogg, flac\n"
     ]
    }
   ],
   "source": [
    "# Create plugin directly\n",
    "plugin = GeminiPlugin()\n",
    "\n",
    "# Check basic properties\n",
    "print(f\"Plugin: {plugin.name} v{plugin.version}\")\n",
    "print(f\"Available: {plugin.is_available()}\")\n",
    "print(f\"Supported formats: {', '.join(plugin.supported_formats)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94f6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration options:\n",
      "- Required: ['model']\n",
      "- Total properties: 17\n",
      "\n",
      "Key configuration properties:\n",
      "  model:\n",
      "    Type: string\n",
      "    Default: gemini-2.5-flash\n",
      "    Description: Gemini model to use for transcription\n",
      "  temperature:\n",
      "    Type: number\n",
      "    Default: 0.0\n",
      "    Description: Sampling temperature\n",
      "  downsample_audio:\n",
      "    Type: boolean\n",
      "    Default: False\n",
      "    Description: Downsample audio before uploading (requires ffmpeg)\n",
      "  prompt:\n",
      "    Type: string\n",
      "    Default: Generate a transcription of the audio, only extract speech and ignore background audio.\n",
      "    Description: Prompt for transcription\n"
     ]
    }
   ],
   "source": [
    "# Get configuration schema\n",
    "schema = plugin.get_config_schema()\n",
    "print(\"Configuration options:\")\n",
    "print(f\"- Required: {schema.get('required', [])}\")\n",
    "print(f\"- Total properties: {len(schema['properties'])}\")\n",
    "print(\"\\nKey configuration properties:\")\n",
    "for prop in ['model', 'temperature', 'downsample_audio', 'prompt']:\n",
    "    prop_schema = schema['properties'][prop]\n",
    "    print(f\"  {prop}:\")\n",
    "    print(f\"    Type: {prop_schema.get('type')}\")\n",
    "    print(f\"    Default: {prop_schema.get('default')}\")\n",
    "    print(f\"    Description: {prop_schema.get('description')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e03138",
   "metadata": {},
   "source": [
    "## Test with Plugin Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604aaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Create plugin manager\n",
    "manager = PluginManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de198170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Loaded plugin from module: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin loaded: True\n"
     ]
    }
   ],
   "source": [
    "# Load plugin from module (for development)\n",
    "import sys\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "# Create a temporary module file\n",
    "temp_plugin_file = Path(\"temp_gemini_plugin.py\")\n",
    "with open(temp_plugin_file, \"w\") as f:\n",
    "    f.write(\"from cjm_transcription_plugin_gemini.plugin import GeminiPlugin\\n\")\n",
    "\n",
    "# Load the plugin\n",
    "# Note: API key must be set in environment or config\n",
    "config = {\"model\": \"gemini-2.5-flash\"}\n",
    "if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "    success = manager.load_plugin_from_module(str(temp_plugin_file), config=config)\n",
    "    print(f\"Plugin loaded: {success}\")\n",
    "else:\n",
    "    print(\"Set GEMINI_API_KEY environment variable to load the plugin\")\n",
    "    success = False\n",
    "\n",
    "# Clean up temp file\n",
    "temp_plugin_file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb37251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins:\n",
      "  - gemini v1.0.0 (enabled: True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available models (36 total):\n",
      "  - gemma-3n-e4b-it\n",
      "  - gemma-3n-e2b-it\n",
      "  - gemma-3-4b-it\n",
      "  - gemma-3-27b-it\n",
      "  - gemma-3-1b-it\n",
      "  - gemma-3-12b-it\n",
      "  - gemini-exp-1206\n",
      "  - gemini-2.5-pro-preview-06-05\n",
      "  - gemini-2.5-pro-preview-05-06\n",
      "  - gemini-2.5-pro-preview-03-25\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # List loaded plugins\n",
    "    print(\"Loaded plugins:\")\n",
    "    for meta in manager.list_plugins():\n",
    "        print(f\"  - {meta.name} v{meta.version} (enabled: {meta.enabled})\")\n",
    "    \n",
    "    # Get available models\n",
    "    gemini_plugin = manager.get_plugin(\"gemini\")\n",
    "    if hasattr(gemini_plugin, 'get_available_models'):\n",
    "        models = gemini_plugin.get_available_models()\n",
    "        print(f\"\\nAvailable models ({len(models)} total):\")\n",
    "        for model in models[:10]:  # Show first 10\n",
    "            print(f\"  - {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02edcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Gemini configuration:\n",
      "{\n",
      "  \"model\": \"gemini-2.5-flash\",\n",
      "  \"temperature\": 0.0,\n",
      "  \"top_p\": 0.95,\n",
      "  \"downsample_audio\": false,\n",
      "  \"safety_settings\": \"OFF\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # Get current configuration\n",
    "    current_config = manager.get_plugin_config(\"gemini\")\n",
    "    print(\"Current Gemini configuration:\")\n",
    "    config_subset = {\n",
    "        k: current_config[k] \n",
    "        for k in [\"model\", \"temperature\", \"top_p\", \"downsample_audio\", \"safety_settings\"] \n",
    "        if k in current_config\n",
    "    }\n",
    "    print(json.dumps(config_subset, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545a0dd",
   "metadata": {},
   "source": [
    "## Test Configuration Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36804bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: switching to 2.0 flash\n",
      "  Config: {'model': 'gemini-2.0-flash'}\n",
      "  Valid: True\n",
      "\n",
      "Invalid: bad model name\n",
      "  Config: {'model': 'invalid_model'}\n",
      "  Valid: False\n",
      "  Error: 'invalid_model' is not one of ['gemma-3n-e4b-it', 'gemma-3n-e2b-it', 'gemma-3-4b-it', 'gemma-3-27b-i...\n",
      "\n",
      "Valid: adjusting temperature\n",
      "  Config: {'temperature': 0.7}\n",
      "  Valid: False\n",
      "  Error: 'model' is a required property\n",
      "\n",
      "Failed validating 'required' in schema:\n",
      "    {'$schema': 'http://json...\n",
      "\n",
      "Invalid: temperature out of range\n",
      "  Config: {'temperature': 3.0}\n",
      "  Valid: False\n",
      "  Error: 'model' is a required property\n",
      "\n",
      "Failed validating 'required' in schema:\n",
      "    {'$schema': 'http://json...\n",
      "\n",
      "Valid: enable downsampling\n",
      "  Config: {'downsample_audio': True, 'downsample_rate': 16000}\n",
      "  Valid: False\n",
      "  Error: 'model' is a required property\n",
      "\n",
      "Failed validating 'required' in schema:\n",
      "    {'$schema': 'http://json...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # Test configuration validation\n",
    "    test_configs = [\n",
    "        ({\"model\": \"gemini-2.0-flash\"}, \"Valid: switching to 2.0 flash\"),\n",
    "        ({\"model\": \"invalid_model\"}, \"Invalid: bad model name\"),\n",
    "        ({\"temperature\": 0.7}, \"Valid: adjusting temperature\"),\n",
    "        ({\"temperature\": 3.0}, \"Invalid: temperature out of range\"),\n",
    "        ({\"downsample_audio\": True, \"downsample_rate\": 16000}, \"Valid: enable downsampling\"),\n",
    "    ]\n",
    "    \n",
    "    for config, description in test_configs:\n",
    "        is_valid, error = manager.validate_plugin_config(\"gemini\", config)\n",
    "        print(f\"{description}\")\n",
    "        print(f\"  Config: {config}\")\n",
    "        print(f\"  Valid: {is_valid}\")\n",
    "        if error:\n",
    "            print(f\"  Error: {error[:100]}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01fdfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Updated configuration for plugin: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration updated: True\n",
      "\n",
      "Updated configuration:\n",
      "  temperature: 0.3\n",
      "  prompt: Transcribe this audio accurately, including any technical terms.\n",
      "  downsample_audio: True\n",
      "  downsample_rate: 16000\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # Update configuration\n",
    "    new_config = {\n",
    "        \"temperature\": 0.3,\n",
    "        \"prompt\": \"Transcribe this audio accurately, including any technical terms.\",\n",
    "        \"downsample_audio\": True,\n",
    "        \"downsample_rate\": 16000\n",
    "    }\n",
    "    \n",
    "    update_success = manager.update_plugin_config(\"gemini\", new_config, merge=True)\n",
    "    print(f\"Configuration updated: {update_success}\")\n",
    "    \n",
    "    if update_success:\n",
    "        updated_config = manager.get_plugin_config(\"gemini\")\n",
    "        print(\"\\nUpdated configuration:\")\n",
    "        for key in new_config:\n",
    "            print(f\"  {key}: {updated_config[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16103210",
   "metadata": {},
   "source": [
    "## Test Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c28661a-b60b-4fb4-983c-2e862adec6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.config import get_config\n",
    "from pathlib import Path\n",
    "\n",
    "config = get_config()\n",
    "project_dir = config.config_path\n",
    "test_dir = project_dir/\"./test_files/\"\n",
    "audio_path = test_dir/\"short_test_audio.mp3\"\n",
    "# audio_path = test_dir/\"constitution_01_unitedstates_128kb.mp3\"\n",
    "assert audio_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aaa7ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created test audio: 2.00 seconds at 16000 Hz\n"
     ]
    }
   ],
   "source": [
    "# Create test audio\n",
    "def create_test_audio():\n",
    "    \"\"\"Create a simple test audio signal.\"\"\"\n",
    "    sample_rate = 16000\n",
    "    duration = 2  # seconds\n",
    "    t = np.linspace(0, duration, sample_rate * duration)\n",
    "    \n",
    "    # Create a simple tone\n",
    "    frequency = 440  # A4 note\n",
    "    audio = 0.3 * np.sin(2 * np.pi * frequency * t)\n",
    "    \n",
    "    # Add some variation\n",
    "    audio += 0.1 * np.sin(2 * np.pi * frequency * 2 * t)\n",
    "    audio += 0.05 * np.random.randn(len(t))  # Add noise\n",
    "    \n",
    "    return AudioData(\n",
    "        samples=audio.astype(np.float32),\n",
    "        sample_rate=sample_rate,\n",
    "        duration=len(audio) / sample_rate,\n",
    "        filepath=None,\n",
    "        metadata={\"description\": \"Test tone signal\"}\n",
    "    )\n",
    "\n",
    "test_audio = create_test_audio()\n",
    "print(f\"Created test audio: {test_audio.duration:.2f} seconds at {test_audio.sample_rate} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc8a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with synthetic audio...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cea94cbb8244a2b6069de46a260d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling:   0%|          | 0.0/2.0s [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Downsampled audio to 16000Hz\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcribing with Gemini model: gemini-2.5-flash (max_tokens: 65536)\n",
      "google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downsampled audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "google_genai.models - INFO - AFC remote call 1 is done.\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcription completed: 2 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription result:\n",
      "  Text: '[High-pitched whine]'\n",
      "  Metadata: {'model': 'gemini-2.5-flash', 'temperature': 0.3, 'top_p': 0.95, 'max_output_tokens': 65536, 'prompt': 'Transcribe this audio accurately, including any technical terms.', 'use_file_upload': False, 'use_streaming': False}\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # Test with synthetic audio (may not produce meaningful text)\n",
    "    try:\n",
    "        print(\"Testing with synthetic audio...\")\n",
    "        result = manager.execute_plugin(\"gemini\", test_audio)\n",
    "        print(\"Transcription result:\")\n",
    "        print(f\"  Text: '{result.text[:200]}...'\" if len(result.text) > 200 else f\"  Text: '{result.text}'\")\n",
    "        print(f\"  Metadata: {result.metadata}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Synthetic audio may not produce meaningful results\")\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b19f4b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb525e699494acdb9b64d6ab8b251d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling:   0%|          | 0.0/28.0s [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Downsampled audio to 16000Hz\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcribing with Gemini model: gemini-2.5-flash (max_tokens: 65536)\n",
      "google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downsampled audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "google_genai.models - INFO - AFC remote call 1 is done.\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcription completed: 43 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription (first 500 chars):\n",
      "November the 10th, Wednesday, 9:00 p.m.\n",
      "\n",
      "I'm standing in a dark alley.\n",
      "\n",
      "After waiting several hours, the time has come.\n",
      "\n",
      "A woman with long dark hair approaches. I have to act, and fast, before she realizes what has happened. I must find out.\n",
      "\n",
      "...(241 total characters)\n",
      "\n",
      "Model used: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # Test with actual audio file if available\n",
    "    if audio_path.exists():\n",
    "        print(f\"Transcribing: {audio_path}\")\n",
    "        \n",
    "        # You can override config at execution time\n",
    "        result = manager.execute_plugin(\n",
    "            \"gemini\", \n",
    "            str(audio_path),\n",
    "            temperature=0.0,  # Override for deterministic output\n",
    "            prompt=\"Provide a detailed transcription of this audio.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTranscription (first 500 chars):\")\n",
    "        print(result.text[:500])\n",
    "        print(f\"\\n...({len(result.text)} total characters)\")\n",
    "        print(f\"\\nModel used: {result.metadata.get('model')}\")\n",
    "    else:\n",
    "        print(f\"Sample audio file not found: {audio_path}\")\n",
    "        print(\"Place an audio file at this path to test real transcription.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92072b9",
   "metadata": {},
   "source": [
    "## Test Downsampling Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78655d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing downsampling feature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Updated configuration for plugin: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original audio: 44100 Hz\n",
      "Will downsample to: 8000 Hz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6028df807474a6bb1f5c24c10a5030c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling:   0%|          | 0.0/2.0s [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Downsampled audio to 8000Hz\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcribing with Gemini model: gemini-2.5-flash (max_tokens: 65536)\n",
      "google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downsampled audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "google_genai.models - INFO - AFC remote call 1 is done.\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcription completed: 3 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling and transcription successful!\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # Test with downsampling enabled\n",
    "    print(\"Testing downsampling feature...\")\n",
    "    \n",
    "    # Update config to enable downsampling\n",
    "    downsample_config = {\n",
    "        \"downsample_audio\": True,\n",
    "        \"downsample_rate\": 8000,  # Very low sample rate\n",
    "        \"downsample_channels\": 1  # Mono\n",
    "    }\n",
    "    \n",
    "    manager.update_plugin_config(\"gemini\", downsample_config, merge=True)\n",
    "    \n",
    "    # Create higher quality audio\n",
    "    hq_audio = AudioData(\n",
    "        samples=np.random.randn(44100 * 2).astype(np.float32) * 0.1,  # 2 seconds at 44.1kHz\n",
    "        sample_rate=44100,\n",
    "        duration=2.0,\n",
    "        filepath=None,\n",
    "        metadata={\"description\": \"High quality test audio\"}\n",
    "    )\n",
    "    \n",
    "    print(f\"Original audio: {hq_audio.sample_rate} Hz\")\n",
    "    print(f\"Will downsample to: {downsample_config['downsample_rate']} Hz\")\n",
    "    \n",
    "    try:\n",
    "        result = manager.execute_plugin(\"gemini\", hq_audio)\n",
    "        print(\"Downsampling and transcription successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Downsampling requires ffmpeg to be installed\")\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3007b6",
   "metadata": {},
   "source": [
    "## Test Entry Point Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce6c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Discovered plugin: gemini v0.0.1 from package cjm-transcription-plugin-gemini\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Loaded plugin: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing entry point discovery:\n",
      "\n",
      "Discovered 1 plugin(s) via entry points:\n",
      "  - gemini v0.0.1 from cjm-transcription-plugin-gemini\n",
      "\n",
      "Loaded gemini: True\n"
     ]
    }
   ],
   "source": [
    "# This will work after installing the package\n",
    "print(\"Testing entry point discovery:\")\n",
    "manager2 = PluginManager()\n",
    "\n",
    "# Discover plugins via entry points\n",
    "discovered = manager2.discover_plugins()\n",
    "print(f\"\\nDiscovered {len(discovered)} plugin(s) via entry points:\")\n",
    "for plugin_meta in discovered:\n",
    "    print(f\"  - {plugin_meta.name} v{plugin_meta.version} from {plugin_meta.package_name}\")\n",
    "\n",
    "# Load discovered Gemini plugin\n",
    "for plugin_meta in discovered:\n",
    "    if plugin_meta.name == \"gemini\":\n",
    "        if os.environ.get(\"GEMINI_API_KEY\"):\n",
    "            success = manager2.load_plugin(plugin_meta, config={\"model\": \"gemini-2.5-flash\"})\n",
    "            print(f\"\\nLoaded {plugin_meta.name}: {success}\")\n",
    "        else:\n",
    "            print(f\"\\nSkipping {plugin_meta.name} - API key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0ec3b-c2a4-4e58-ab11-eeea7e85c2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ypu9vd2raok",
   "metadata": {},
   "source": [
    "## Test File Upload Feature\n",
    "\n",
    "Test uploading audio files to Gemini API instead of embedding them in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ucmjvn7xw4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing file upload feature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Updated configuration for plugin: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading and transcribing: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c04bfc46774850b45e5909e8eaf4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling:   0%|          | 0.0/28.0s [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Downsampled audio to 8000Hz\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Uploading audio file: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio_downsampled.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downsampled audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH88nTxqFvpwje9Ub-isiDEhR9PopHcv9FYhSOKdp98qSj1dd1rM_ehS6tFkwdotSaXggS7h0AIkc8LMTMFKt94AZWLpQTSlZmIH4jnduKw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Successfully uploaded file: files/i8z50jexg28t\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcribing with Gemini model: gemini-2.5-flash (max_tokens: 65536)\n",
      "google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "google_genai.models - INFO - AFC remote call 1 is done.\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcription completed: 43 words\n",
      "httpx - INFO - HTTP Request: DELETE https://generativelanguage.googleapis.com/v1beta/files/i8z50jexg28t \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Deleted uploaded file: files/i8z50jexg28t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription (first 300 chars):\n",
      "November the 10th, Wednesday.\n",
      "9 PM.\n",
      "I'm standing in a dark alley.\n",
      "After waiting several hours, the time has come.\n",
      "A woman with long, dark hair approaches.\n",
      "I have to act, and fast, before she realizes what has happened.\n",
      "I must find out.\n",
      "\n",
      "Metadata:\n",
      "  Used file upload: True\n",
      "  Used streaming: False\n",
      "  Model: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "if success and audio_path.exists():\n",
    "    # Test with file upload enabled\n",
    "    print(\"Testing file upload feature...\")\n",
    "    \n",
    "    # Update config to use file upload\n",
    "    upload_config = {\n",
    "        \"use_file_upload\": True,\n",
    "        \"delete_uploaded_files\": True  # Automatically delete after transcription\n",
    "    }\n",
    "    \n",
    "    manager.update_plugin_config(\"gemini\", upload_config, merge=True)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Uploading and transcribing: {audio_path}\")\n",
    "        result = manager.execute_plugin(\n",
    "            \"gemini\", \n",
    "            str(audio_path),\n",
    "            temperature=0.0,\n",
    "            prompt=\"Provide a detailed transcription of this audio.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTranscription (first 300 chars):\")\n",
    "        print(result.text[:300])\n",
    "        print(f\"\\nMetadata:\")\n",
    "        print(f\"  Used file upload: {result.metadata.get('use_file_upload')}\")\n",
    "        print(f\"  Used streaming: {result.metadata.get('use_streaming')}\")\n",
    "        print(f\"  Model: {result.metadata.get('model')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during file upload test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g86vg3j9egb",
   "metadata": {},
   "source": [
    "## Test Streaming Feature\n",
    "\n",
    "Test streaming transcription responses for real-time output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ffvrsnm3vo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing streaming feature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Updated configuration for plugin: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming transcription for: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444978938c7542f08343d5ce45a7aa8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling:   0%|          | 0.0/28.0s [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Downsampled audio to 8000Hz\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcribing with Gemini model: gemini-2.5-flash (max_tokens: 65536)\n",
      "google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "google_genai.models - INFO - AFC remote call 1 is done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downsampled audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Streaming transcription completed\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcription completed: 43 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription (first 300 chars):\n",
      "November the 10th, Wednesday. 9:00 p.m. I'm standing in a dark alley. After waiting several hours, the time has come. A woman with long dark hair approaches. I have to act and fast, before she realizes what has happened. I must find out.\n",
      "\n",
      "Metadata:\n",
      "  Used file upload: False\n",
      "  Used streaming: True\n",
      "  Total words: 43\n"
     ]
    }
   ],
   "source": [
    "if success and audio_path.exists():\n",
    "    # Test with streaming enabled\n",
    "    print(\"Testing streaming feature...\")\n",
    "    \n",
    "    # Update config to use streaming\n",
    "    streaming_config = {\n",
    "        \"use_file_upload\": False,  # Can combine with file upload if desired\n",
    "        \"use_streaming\": True\n",
    "    }\n",
    "    \n",
    "    manager.update_plugin_config(\"gemini\", streaming_config, merge=True)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Streaming transcription for: {audio_path}\")\n",
    "        result = manager.execute_plugin(\n",
    "            \"gemini\", \n",
    "            str(audio_path),\n",
    "            temperature=0.0,\n",
    "            prompt=\"Transcribe this audio.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTranscription (first 300 chars):\")\n",
    "        print(result.text[:300])\n",
    "        print(f\"\\nMetadata:\")\n",
    "        print(f\"  Used file upload: {result.metadata.get('use_file_upload')}\")\n",
    "        print(f\"  Used streaming: {result.metadata.get('use_streaming')}\")\n",
    "        print(f\"  Total words: {len(result.text.split())}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during streaming test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7chtw9joc0e",
   "metadata": {},
   "source": [
    "## Test Combined Features\n",
    "\n",
    "Test using both file upload and streaming together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "y6762k5k1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Updated configuration for plugin: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combined file upload + streaming...\n",
      "Uploading and streaming transcription for: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbdb43a9ea64ae0a81989dffd580726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling:   0%|          | 0.0/28.0s [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Downsampled audio to 8000Hz\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Uploading audio file: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio_downsampled.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downsampled audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89o9sMVJ2Hse6KhF4gZLsylEMxi1MPSUVtXrkihRV9nIFwpduydMITwFV_nYOuoSjWnohbXYiXLxpjAwZmotay4huV8fwJh4hFgZ4f3Wbk&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Successfully uploaded file: files/gyhscrcgzy8h\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcribing with Gemini model: gemini-2.5-flash (max_tokens: 65536)\n",
      "google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "google_genai.models - INFO - AFC remote call 1 is done.\n",
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Streaming transcription completed\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcription completed: 43 words\n",
      "httpx - INFO - HTTP Request: DELETE https://generativelanguage.googleapis.com/v1beta/files/gyhscrcgzy8h \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Deleted uploaded file: files/gyhscrcgzy8h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription (first 400 chars):\n",
      "November the 10th, Wednesday, 9 p.m.\n",
      "\n",
      "I'm standing in a dark alley.\n",
      "\n",
      "After waiting several hours, the time has come.\n",
      "\n",
      "A woman with long, dark hair approaches.\n",
      "I have to act, and fast, before she realizes what has happened.\n",
      "I must find out.\n",
      "\n",
      "Metadata:\n",
      "  model: gemini-2.5-flash\n",
      "  temperature: 0.0\n",
      "  top_p: 0.95\n",
      "  max_output_tokens: 65536\n",
      "  prompt: Generate a detailed and accurate transcription.\n",
      "  use_file_upload: True\n",
      "  use_streaming: True\n"
     ]
    }
   ],
   "source": [
    "if success and audio_path.exists():\n",
    "    # Test with both file upload and streaming\n",
    "    print(\"Testing combined file upload + streaming...\")\n",
    "    \n",
    "    # Update config to use both features\n",
    "    combined_config = {\n",
    "        \"use_file_upload\": True,\n",
    "        \"use_streaming\": True,\n",
    "        \"delete_uploaded_files\": True\n",
    "    }\n",
    "    \n",
    "    manager.update_plugin_config(\"gemini\", combined_config, merge=True)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Uploading and streaming transcription for: {audio_path}\")\n",
    "        \n",
    "        # You can also test with different models\n",
    "        result = manager.execute_plugin(\n",
    "            \"gemini\", \n",
    "            str(audio_path),\n",
    "            model=\"gemini-2.5-flash\",  # Or any available model\n",
    "            temperature=0.0,\n",
    "            prompt=\"Generate a detailed and accurate transcription.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTranscription (first 400 chars):\")\n",
    "        print(result.text[:400])\n",
    "        print(f\"\\nMetadata:\")\n",
    "        for key, value in result.metadata.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during combined features test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5zxlxoqtsh",
   "metadata": {},
   "source": [
    "## Test File Management\n",
    "\n",
    "Test that uploaded files are properly tracked and cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6hsftfzt6j",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing file management and cleanup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Updated configuration for plugin: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file without auto-deletion...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b53efe5b71443590d77dd6223f35cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling:   0%|          | 0.0/28.0s [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Downsampled audio to 8000Hz\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Uploading audio file: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio_downsampled.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downsampled audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH89EyQYyLHQurvaqvItGTKvaL6INs1-2YiUrubrTooeQhSmoHBXkpIahAyAQWK5WZSzSE4Yy9gajN3ScBoB1Le_3g09hKtuBxFr2RTv6cw&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Successfully uploaded file: files/e68ui1wx4jvp\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcribing with Gemini model: gemini-2.5-flash (max_tokens: 65536)\n",
      "google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "google_genai.models - INFO - AFC remote call 1 is done.\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Transcription completed: 43 words\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n",
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tracked uploaded files: 1\n",
      "  - files/e68ui1wx4jvp\n",
      "\n",
      "Manually cleaning up...\n",
      "Files after cleanup: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: GET https://generativelanguage.googleapis.com/v1beta/models?pageToken=Ch5tb2RlbHMvaW1hZ2VuLTMuMC1nZW5lcmF0ZS0wMDI%3D \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Found 36 audio-capable models\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Updated max_output_tokens to 65536 for model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Initialized Gemini plugin with model 'gemini-2.5-flash'\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Updated configuration for plugin: gemini\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # Test file management with multiple uploads\n",
    "    print(\"Testing file management and cleanup...\")\n",
    "    \n",
    "    # Create a test plugin instance directly to track uploaded files\n",
    "    test_plugin = manager.get_plugin(\"gemini\")\n",
    "    \n",
    "    # Configure to NOT auto-delete to test manual cleanup\n",
    "    no_delete_config = {\n",
    "        \"use_file_upload\": True,\n",
    "        \"use_streaming\": False,\n",
    "        \"delete_uploaded_files\": False  # Keep files for manual deletion\n",
    "    }\n",
    "    \n",
    "    manager.update_plugin_config(\"gemini\", no_delete_config, merge=True)\n",
    "    \n",
    "    try:\n",
    "        # Upload and transcribe without auto-deletion\n",
    "        print(\"Uploading file without auto-deletion...\")\n",
    "        result = manager.execute_plugin(\n",
    "            \"gemini\", \n",
    "            str(audio_path),\n",
    "            prompt=\"Quick transcription test.\"\n",
    "        )\n",
    "        \n",
    "        # Check tracked files\n",
    "        print(f\"\\nTracked uploaded files: {len(test_plugin.uploaded_files)}\")\n",
    "        if test_plugin.uploaded_files:\n",
    "            for file in test_plugin.uploaded_files:\n",
    "                print(f\"  - {file.name}\")\n",
    "        \n",
    "        # Now test cleanup\n",
    "        print(\"\\nManually cleaning up...\")\n",
    "        test_plugin.cleanup()\n",
    "        \n",
    "        print(f\"Files after cleanup: {len(test_plugin.uploaded_files)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during file management test: {e}\")\n",
    "    \n",
    "    # Reset to auto-delete\n",
    "    manager.update_plugin_config(\"gemini\", {\"delete_uploaded_files\": True}, merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1kvrb30gzfu",
   "metadata": {},
   "source": [
    "## Test Streaming with execute_stream Method\n",
    "\n",
    "Test the new execute_stream method that yields chunks in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "l0nlikq6n5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Using streaming mode for plugin gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing execute_stream method...\n",
      "Plugin supports streaming: True\n",
      "\n",
      "Streaming transcription for: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio.mp3\n",
      "Chunks as they arrive:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb520da4443e40ec90240c76d749d4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling:   0%|          | 0.0/28.0s [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Downsampled audio to 8000Hz\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Uploading audio file: /mnt/SN850X_8TB_EXT4/Projects/GitHub/cj-mills/cjm-transcription-plugin-gemini/test_files/short_test_audio_downsampled.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully downsampled audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files \"HTTP/1.1 200 OK\"\n",
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/upload/v1beta/files?upload_id=ABgVH8_we0NtJ8tiXM17RCrfDGTFfIhYRZE_jzf9cPqQCwcWf1kRSMkas_ab6QdAAE4J9iMm0jrqWWYXY9P-AnzCsz2yjFVzsypDLT49z_PlsSc&upload_protocol=resumable \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Successfully uploaded file: files/iylb8b2ro0sv\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Streaming transcription with Gemini model: gemini-2.5-flash (max_tokens: 65536)\n",
      "google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "google_genai.models - INFO - AFC remote call 1 is done.\n",
      "httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Streaming completed: 2 chunks, 43 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk 1]: November the 10th, Wednesday, 9 PM.\n",
      "\n",
      "I'm standing ...\n",
      "[Chunk 2]:  fast, before she realizes what has happened.\n",
      "I mu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "httpx - INFO - HTTP Request: DELETE https://generativelanguage.googleapis.com/v1beta/files/iylb8b2ro0sv \"HTTP/1.1 200 OK\"\n",
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Deleted uploaded file: files/iylb8b2ro0sv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "Total chunks received: 2\n",
      "Complete transcription: November the 10th, Wednesday, 9 PM.\n",
      "\n",
      "I'm standing in a dark alley.\n",
      "\n",
      "After waiting several hours, the time has come.\n",
      "\n",
      "A woman with long dark hair approaches.\n",
      "\n",
      "I have to act, and fast, before she realiz...\n",
      "\n",
      "All plugins with streaming support: ['gemini']\n"
     ]
    }
   ],
   "source": [
    "if success and audio_path.exists():\n",
    "    # Test the new execute_stream method\n",
    "    print(\"Testing execute_stream method...\")\n",
    "    \n",
    "    # Check if plugin supports streaming\n",
    "    supports_streaming = manager.check_streaming_support(\"gemini\")\n",
    "    print(f\"Plugin supports streaming: {supports_streaming}\")\n",
    "    \n",
    "    if supports_streaming:\n",
    "        print(f\"\\nStreaming transcription for: {audio_path}\")\n",
    "        print(\"Chunks as they arrive:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        chunks = []\n",
    "        chunk_count = 0\n",
    "        \n",
    "        # Stream transcription chunks\n",
    "        for chunk in manager.execute_plugin_stream(\"gemini\", str(audio_path)):\n",
    "            chunk_count += 1\n",
    "            chunks.append(chunk)\n",
    "            print(f\"[Chunk {chunk_count}]: {chunk[:50]}...\" if len(chunk) > 50 else f\"[Chunk {chunk_count}]: {chunk}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "        print(f\"\\nTotal chunks received: {chunk_count}\")\n",
    "        print(f\"Complete transcription: {''.join(chunks)[:200]}...\")\n",
    "        \n",
    "        # Get list of all streaming-capable plugins\n",
    "        streaming_plugins = manager.get_streaming_plugins()\n",
    "        print(f\"\\nAll plugins with streaming support: {streaming_plugins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf33a7d-f5a5-4e5d-a1e4-3bdc50770004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8f254-5af3-4125-be40-8fc9c396b5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c2b093-3f0d-4709-9867-325311eaa1ba",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "102de879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cjm_transcription_plugin_gemini.plugin.GeminiPlugin - INFO - Cleanup completed\n",
      "cjm_transcription_plugin_system.plugin_manager.PluginManager - INFO - Unloaded plugin: gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up...\n",
      "Plugins remaining: 0\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # Clean up\n",
    "    print(\"Cleaning up...\")\n",
    "    manager.unload_plugin(\"gemini\")\n",
    "    print(f\"Plugins remaining: {len(manager.list_plugins())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
